{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1024])\n",
      "torch.Size([384, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# def matmul_by_blocks(tensor_0, tensor_1,block_size=128,topology=None):\n",
    "#     out_matrix = torch.empty(tensor_0.size(0),tensor_1.size(1),dtype=torch.bfloat16)\n",
    "#     #going from the upper left of tensor 0.\n",
    "#     upper_left = tensor_0[:block_size,:block_size]\n",
    "#     #just hardcoding the token assignments that we'd get from topology\n",
    "\n",
    "x = torch.rand((256+384), 256, device='cuda', dtype=torch.bfloat16)\n",
    "w1 = torch.rand(256, 1024*2, device='cuda', dtype=torch.bfloat16) #hidden size, ffn*2 experts\n",
    "\n",
    "expert_0_computed = x[:256]@w1[:,:1024]\n",
    "expert_1_computed = x[256:]@w1[:,1024:]\n",
    "print(expert_0_computed.shape)\n",
    "print(expert_1_computed.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) before\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [57.7500, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [58.5000, 63.0000, 66.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [57.7500, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [58.5000, 63.0000, 66.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [57.7500, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [58.5000, 63.0000, 66.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [57.7500, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [58.5000, 63.0000, 66.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [57.7500, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [58.5000, 63.0000, 66.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [57.7500, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [58.5000, 63.0000, 66.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [57.7500, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [58.5000, 63.0000, 66.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [60.7500, 61.7500, 62.5000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [60.7500, 61.7500, 62.5000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [60.7500, 61.7500, 62.5000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [60.7500, 61.7500, 62.5000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [60.7500, 61.7500, 62.5000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [60.7500, 61.7500, 62.5000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [60.7500, 61.7500, 62.5000,  ...,  0.0000,  0.0000,  0.0000]]) during\n",
      "tensor([[59.7500, 59.5000, 62.5000,  ..., 65.5000, 61.2500, 60.2500],\n",
      "        [57.7500, 62.2500, 65.0000,  ..., 68.0000, 61.5000, 62.5000],\n",
      "        [58.5000, 63.0000, 66.5000,  ..., 73.0000, 65.5000, 66.5000],\n",
      "        ...,\n",
      "        [58.7500, 67.5000, 67.0000,  ..., 70.5000, 63.7500, 66.0000],\n",
      "        [54.5000, 62.2500, 65.0000,  ..., 64.5000, 59.7500, 59.5000],\n",
      "        [60.7500, 61.7500, 62.5000,  ..., 66.5000, 60.0000, 62.0000]]) during\n"
     ]
    }
   ],
   "source": [
    "out_matrix = torch.zeros((256,1024))\n",
    "print(out_matrix, \"before\")\n",
    "for i in range(0,256,128):\n",
    "    for j in range(0,1024,128):\n",
    "        out_block = x[i:i+128]@w1[:,j:j+128]\n",
    "        out_matrix[i:i+128,j:j+128] = out_block\n",
    "        print(out_matrix, \"during\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from einops import rearrange\n",
    "from moe import sdd_kernel\n",
    "from model import MoeMLP, MoeMLPForLoop\n",
    "from tqdm import tqdm\n",
    "@dataclass\n",
    "class ToyMoEConfig:\n",
    "    n_embd: int = 256\n",
    "    num_experts: int = 4\n",
    "    num_experts_per_tok: int = 2\n",
    "    norm_topk_prob: bool = True\n",
    "    bias: bool = True\n",
    "    dropout: float = 0.0\n",
    "config = ToyMoEConfig()\n",
    "\n",
    "# Create toy input\n",
    "batch_size = 64\n",
    "seq_len = 8192\n",
    "x = torch.randn(batch_size, seq_len, config.n_embd,device='cuda')\n",
    "# print(f\"\\nInput shape: {x.shape}\")\n",
    "\n",
    "# Create MoeMLP instance\n",
    "moe_mlp = MoeMLP(config).cuda()\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\n=== Forward Pass ===\")\n",
    "block_sparse, router_logits, debug_info = moe_mlp(x)\n",
    "print(f\"\\nForward pass completed!\")\n",
    "print(f\"Router logits shape: {router_logits.shape}\")\n",
    "print(f\"Triton output shape: {block_sparse.shape}\")\n",
    "\n",
    "# Extract debug variables\n",
    "col_indices_ptr = debug_info['col_indices_ptr']\n",
    "row_indices_ptr = debug_info['row_indices_ptr']\n",
    "selected_experts = debug_info['selected_experts']\n",
    "selected_experts_sorted = debug_info['selected_experts_sorted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check which experts are being used\n",
    "print(\"=== EXPERT USAGE ANALYSIS ===\")\n",
    "print(\"col_indices_ptr:\", col_indices_ptr)\n",
    "\n",
    "# Use the debug info from the forward pass\n",
    "selected_experts_flat = selected_experts.reshape(-1)\n",
    "\n",
    "print(\"selected_experts_sorted (first 20):\", selected_experts_sorted[:20])\n",
    "print(\"selected_experts_flat (first 20):\", selected_experts_flat[:20])\n",
    "\n",
    "print(\"\\nExpert distribution:\")\n",
    "for i in range(config.num_experts):\n",
    "    count = (selected_experts_flat == i).sum()\n",
    "    print(f\"  Expert {i}: {count} blocks ({count/len(selected_experts_flat)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nRouter logits sample (first 5 tokens):\")\n",
    "print(router_logits[:5])\n",
    "\n",
    "print(\"\\nSelected experts (first 10 tokens):\")\n",
    "print(selected_experts[:10])\n",
    "\n",
    "# Get router weights for display\n",
    "router_weights = F.softmax(router_logits, dim=1, dtype=torch.float)\n",
    "router_weights_topk, _ = torch.topk(router_weights, config.num_experts_per_tok, dim=-1)\n",
    "if config.norm_topk_prob:\n",
    "    router_weights_topk /= router_weights_topk.sum(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"\\nRouter weights (first 5 tokens):\")\n",
    "print(router_weights_topk[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Analyze block_sparse pattern\n",
    "print(\"=== BLOCK_SPARSE PATTERN ANALYSIS ===\")\n",
    "print(f\"block_sparse shape: {block_sparse.shape}\")\n",
    "\n",
    "# Check if certain columns are always zero\n",
    "nonzero_cols = torch.any(block_sparse != 0, dim=0)\n",
    "print(f\"Non-zero columns: {torch.sum(nonzero_cols)} out of {block_sparse.shape[1]}\")\n",
    "\n",
    "if torch.sum(nonzero_cols) > 0:\n",
    "    first_nonzero = torch.argmax(nonzero_cols.float())\n",
    "    last_nonzero = len(nonzero_cols) - 1 - torch.argmax(torch.flip(nonzero_cols.float(), [0]))\n",
    "    print(f\"First non-zero col: {first_nonzero}\")\n",
    "    print(f\"Last non-zero col: {last_nonzero}\")\n",
    "    print(f\"Non-zero range: columns {first_nonzero} to {last_nonzero}\")\n",
    "\n",
    "# Check weight matrix structure\n",
    "print(f\"\\nWeight matrix w1 shape: {moe_mlp.w1.shape}\")\n",
    "print(f\"d_ffn per expert: {moe_mlp.d_ffn}\")\n",
    "print(f\"Total experts: {config.num_experts}\")\n",
    "print(f\"Expected w1 width: {moe_mlp.d_ffn * config.num_experts}\")\n",
    "\n",
    "# Show which parts of w1 should correspond to each expert\n",
    "print(f\"\\nExpert weight matrix ranges:\")\n",
    "for i in range(config.num_experts):\n",
    "    start_col = i * moe_mlp.d_ffn\n",
    "    end_col = (i + 1) * moe_mlp.d_ffn\n",
    "    print(f\"  Expert {i}: columns {start_col} to {end_col-1}\")\n",
    "\n",
    "# Check basic stats\n",
    "print(f\"\\nblock_sparse stats:\")\n",
    "print(f\"  Non-zero elements: {torch.count_nonzero(block_sparse)}\")\n",
    "print(f\"  Min value: {block_sparse.min():.6f}\")\n",
    "print(f\"  Max value: {block_sparse.max():.6f}\")\n",
    "print(f\"  Mean: {block_sparse.mean():.6f}\")\n",
    "print(f\"  Std: {block_sparse.std():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check kernel indexing calculation\n",
    "print(\"=== KERNEL INDEXING DEBUG ===\")\n",
    "\n",
    "# Show the relationship between col_indices_ptr and the actual expert columns in w1\n",
    "print(f\"BLOCK_N: {moe_mlp.BLOCK_N}\")\n",
    "print(f\"col_indices_ptr: {col_indices_ptr}\")\n",
    "\n",
    "for i, expert_id in enumerate(col_indices_ptr):\n",
    "    expected_col_start = expert_id * moe_mlp.BLOCK_N  # This is what the kernel calculates\n",
    "    actual_expert_start = expert_id * moe_mlp.d_ffn   # This is where expert weights actually are\n",
    "    print(f\"Block {i}: expert_id={expert_id}\")\n",
    "    print(f\"  Kernel will use columns {expected_col_start} to {expected_col_start + moe_mlp.BLOCK_N - 1}\")\n",
    "    print(f\"  Expert {expert_id} weights are at columns {actual_expert_start} to {actual_expert_start + moe_mlp.d_ffn - 1}\")\n",
    "    print(f\"  Match: {expected_col_start == actual_expert_start and moe_mlp.BLOCK_N == moe_mlp.d_ffn}\")\n",
    "\n",
    "# Test with a simple manual calculation to verify the kernel is working\n",
    "print(f\"\\n=== MANUAL VERIFICATION ===\")\n",
    "print(f\"If all tokens use expert 0, we should see non-zeros in columns 0 to {moe_mlp.d_ffn-1}\")\n",
    "print(f\"If all tokens use expert 1, we should see non-zeros in columns {moe_mlp.d_ffn} to {2*moe_mlp.d_ffn-1}\")\n",
    "\n",
    "# Check the actual pattern\n",
    "active_regions = []\n",
    "for i in range(config.num_experts):\n",
    "    start_col = i * moe_mlp.d_ffn\n",
    "    end_col = (i + 1) * moe_mlp.d_ffn\n",
    "    region_has_values = torch.any(block_sparse[:, start_col:end_col] != 0)\n",
    "    active_regions.append(region_has_values.item())\n",
    "    print(f\"Expert {i} region (cols {start_col}-{end_col-1}): {'ACTIVE' if region_has_values else 'INACTIVE'}\")\n",
    "\n",
    "print(f\"\\nActive expert regions: {[i for i, active in enumerate(active_regions) if active]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the FULL block_sparse tensor (as requested)\n",
    "print(\"=== FULL BLOCK_SPARSE TENSOR ===\")\n",
    "torch.set_printoptions(threshold=float('inf'), linewidth=200)\n",
    "print(\"block_sparse (full tensor):\")\n",
    "print(block_sparse[-1][-513:])\n",
    "\n",
    "# Reset print options to default\n",
    "torch.set_printoptions(profile=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_block_sparse(block_sparse, block_size=128):\n",
    "    \"\"\"Visualize a block-sparse matrix by showing which blocks are non-zero\"\"\"\n",
    "    \n",
    "    # Get dimensions\n",
    "    M, N = block_sparse.shape\n",
    "    blocks_m = (M + block_size - 1) // block_size\n",
    "    blocks_n = (N + block_size - 1) // block_size\n",
    "    \n",
    "    # Create a grid showing which blocks have any non-zero values\n",
    "    block_grid = torch.zeros(blocks_m, blocks_n)\n",
    "    \n",
    "    for i in range(blocks_m):\n",
    "        for j in range(blocks_n):\n",
    "            # Extract the block\n",
    "            row_start = i * block_size\n",
    "            row_end = min((i + 1) * block_size, M)\n",
    "            col_start = j * block_size\n",
    "            col_end = min((j + 1) * block_size, N)\n",
    "            \n",
    "            block = block_sparse[row_start:row_end, col_start:col_end]\n",
    "            \n",
    "            # Check if block has any non-zero values\n",
    "            if torch.any(torch.abs(block) > 1e-6):\n",
    "                block_grid[i, j] = 1\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Show the block pattern\n",
    "    im = ax.imshow(block_grid.cpu().numpy(), cmap='Blues', aspect='auto')\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(blocks_m + 1):\n",
    "        ax.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
    "    for j in range(blocks_n + 1):\n",
    "        ax.axvline(j - 0.5, color='gray', linewidth=0.5)\n",
    "    \n",
    "    # Add expert boundaries (assuming 4 blocks per expert)\n",
    "    blocks_per_expert = 4  # 512 columns / 128 = 4\n",
    "    for e in range(0, blocks_n, blocks_per_expert):\n",
    "        ax.axvline(e - 0.5, color='red', linewidth=2)\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel(f'Column Blocks (each = {block_size} columns)')\n",
    "    ax.set_ylabel(f'Row Blocks (each = {block_size} tokens)')\n",
    "    ax.set_title(f'Block-Sparse Pattern ({blocks_m}×{blocks_n} blocks of size {block_size}×{block_size})')\n",
    "    \n",
    "    # Add expert labels on x-axis\n",
    "    expert_positions = [i * blocks_per_expert + blocks_per_expert/2 - 0.5 for i in range(4)]\n",
    "    ax.set_xticks(expert_positions)\n",
    "    ax.set_xticklabels([f'Expert {i}' for i in range(4)])\n",
    "    \n",
    "    plt.colorbar(im, ax=ax, label='Block Active')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return block_grid\n",
    "\n",
    "# Use it on your matrix\n",
    "block_pattern = visualize_block_sparse(block_sparse)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Total blocks: {block_pattern.numel()}\")\n",
    "print(f\"Active blocks: {torch.sum(block_pattern).item()}\")\n",
    "print(f\"Sparsity: {1 - torch.sum(block_pattern).item() / block_pattern.numel():.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
