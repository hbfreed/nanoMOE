{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: ToyMoEConfig(n_embd=32, num_experts=8, num_experts_per_tok=2, norm_topk_prob=True, bias=True, dropout=0.0)\n",
      "Input shape: torch.Size([4, 8, 32])\n",
      "\n",
      "Flattened input shape: torch.Size([32, 32])\n",
      "num_tokens = 32\n",
      "Router logits shape: torch.Size([32, 8])\n",
      "Router weights shape: torch.Size([32, 2])\n",
      "Selected experts shape: torch.Size([32, 2])\n",
      "Selected experts:\n",
      "tensor([[4, 6],\n",
      "        [5, 7],\n",
      "        [2, 0],\n",
      "        [4, 5],\n",
      "        [5, 6],\n",
      "        [1, 5],\n",
      "        [7, 2],\n",
      "        [3, 5],\n",
      "        [4, 6],\n",
      "        [4, 3],\n",
      "        [6, 1],\n",
      "        [2, 3],\n",
      "        [2, 0],\n",
      "        [2, 5],\n",
      "        [7, 2],\n",
      "        [7, 2],\n",
      "        [4, 3],\n",
      "        [6, 0],\n",
      "        [4, 0],\n",
      "        [5, 3],\n",
      "        [0, 5],\n",
      "        [7, 3],\n",
      "        [3, 4],\n",
      "        [0, 1],\n",
      "        [1, 5],\n",
      "        [2, 7],\n",
      "        [0, 4],\n",
      "        [3, 6],\n",
      "        [2, 0],\n",
      "        [2, 7],\n",
      "        [2, 6],\n",
      "        [1, 7]])\n",
      "Expert mask shape: torch.Size([32, 2, 8])\n",
      "Rearranged expert mask shape: torch.Size([8, 2, 32])\n",
      "w1 shape: torch.Size([32, 1024])\n",
      "w2 shape: torch.Size([1024, 32])\n",
      "\n",
      "=== Parameters for sdd_kernel call ===\n",
      "M (num_tokens): 32\n",
      "N (ffn_hidden * num_experts): 1024\n",
      "K (hidden_size): 32\n",
      "N (corrected, ffn_hidden * num_experts_per_tok): 256\n",
      "\n",
      "Tokens per expert: tensor([ 8,  5, 11,  8,  8,  9,  7,  8])\n",
      "Total active assignments: 64\n",
      "=== Creating sparse indices for kernel ===\n",
      "Number of active blocks: 64\n",
      "Row indices (which token): tensor([ 0,  0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,\n",
      "         9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17,\n",
      "        18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26,\n",
      "        27, 27, 28, 28, 29, 29, 30, 30, 31, 31])\n",
      "Col indices (which expert): tensor([4, 6, 5, 7, 2, 0, 4, 5, 5, 6, 1, 5, 7, 2, 3, 5, 4, 6, 4, 3, 6, 1, 2, 3,\n",
      "        2, 0, 2, 5, 7, 2, 7, 2, 4, 3, 6, 0, 4, 0, 5, 3, 0, 5, 7, 3, 3, 4, 0, 1,\n",
      "        1, 5, 2, 7, 0, 4, 3, 6, 2, 0, 2, 7, 2, 6, 1, 7])\n",
      "\n",
      "Active blocks mapping:\n",
      "  Block 0: Token 0 -> Expert 4 (weight: 0.7716)\n",
      "  Block 1: Token 0 -> Expert 6 (weight: 0.2284)\n",
      "  Block 2: Token 1 -> Expert 5 (weight: 0.5754)\n",
      "  Block 3: Token 1 -> Expert 7 (weight: 0.4246)\n",
      "  Block 4: Token 2 -> Expert 2 (weight: 0.5387)\n",
      "  Block 5: Token 2 -> Expert 0 (weight: 0.4613)\n",
      "  Block 6: Token 3 -> Expert 4 (weight: 0.5431)\n",
      "  Block 7: Token 3 -> Expert 5 (weight: 0.4569)\n",
      "  Block 8: Token 4 -> Expert 5 (weight: 0.5059)\n",
      "  Block 9: Token 4 -> Expert 6 (weight: 0.4941)\n",
      "  Block 10: Token 5 -> Expert 1 (weight: 0.5039)\n",
      "  Block 11: Token 5 -> Expert 5 (weight: 0.4961)\n",
      "  Block 12: Token 6 -> Expert 7 (weight: 0.6359)\n",
      "  Block 13: Token 6 -> Expert 2 (weight: 0.3641)\n",
      "  Block 14: Token 7 -> Expert 3 (weight: 0.6832)\n",
      "  Block 15: Token 7 -> Expert 5 (weight: 0.3168)\n",
      "  Block 16: Token 8 -> Expert 4 (weight: 0.5934)\n",
      "  Block 17: Token 8 -> Expert 6 (weight: 0.4066)\n",
      "  Block 18: Token 9 -> Expert 4 (weight: 0.6840)\n",
      "  Block 19: Token 9 -> Expert 3 (weight: 0.3160)\n",
      "  Block 20: Token 10 -> Expert 6 (weight: 0.6364)\n",
      "  Block 21: Token 10 -> Expert 1 (weight: 0.3636)\n",
      "  Block 22: Token 11 -> Expert 2 (weight: 0.5509)\n",
      "  Block 23: Token 11 -> Expert 3 (weight: 0.4491)\n",
      "  Block 24: Token 12 -> Expert 2 (weight: 0.5317)\n",
      "  Block 25: Token 12 -> Expert 0 (weight: 0.4683)\n",
      "  Block 26: Token 13 -> Expert 2 (weight: 0.5406)\n",
      "  Block 27: Token 13 -> Expert 5 (weight: 0.4594)\n",
      "  Block 28: Token 14 -> Expert 7 (weight: 0.5780)\n",
      "  Block 29: Token 14 -> Expert 2 (weight: 0.4220)\n",
      "  Block 30: Token 15 -> Expert 7 (weight: 0.6685)\n",
      "  Block 31: Token 15 -> Expert 2 (weight: 0.3315)\n",
      "  Block 32: Token 16 -> Expert 4 (weight: 0.5680)\n",
      "  Block 33: Token 16 -> Expert 3 (weight: 0.4320)\n",
      "  Block 34: Token 17 -> Expert 6 (weight: 0.6637)\n",
      "  Block 35: Token 17 -> Expert 0 (weight: 0.3363)\n",
      "  Block 36: Token 18 -> Expert 4 (weight: 0.7535)\n",
      "  Block 37: Token 18 -> Expert 0 (weight: 0.2465)\n",
      "  Block 38: Token 19 -> Expert 5 (weight: 0.5004)\n",
      "  Block 39: Token 19 -> Expert 3 (weight: 0.4996)\n",
      "  Block 40: Token 20 -> Expert 0 (weight: 0.5877)\n",
      "  Block 41: Token 20 -> Expert 5 (weight: 0.4123)\n",
      "  Block 42: Token 21 -> Expert 7 (weight: 0.5168)\n",
      "  Block 43: Token 21 -> Expert 3 (weight: 0.4832)\n",
      "  Block 44: Token 22 -> Expert 3 (weight: 0.5823)\n",
      "  Block 45: Token 22 -> Expert 4 (weight: 0.4177)\n",
      "  Block 46: Token 23 -> Expert 0 (weight: 0.7123)\n",
      "  Block 47: Token 23 -> Expert 1 (weight: 0.2877)\n",
      "  Block 48: Token 24 -> Expert 1 (weight: 0.5077)\n",
      "  Block 49: Token 24 -> Expert 5 (weight: 0.4923)\n",
      "  Block 50: Token 25 -> Expert 2 (weight: 0.5502)\n",
      "  Block 51: Token 25 -> Expert 7 (weight: 0.4498)\n",
      "  Block 52: Token 26 -> Expert 0 (weight: 0.6098)\n",
      "  Block 53: Token 26 -> Expert 4 (weight: 0.3902)\n",
      "  Block 54: Token 27 -> Expert 3 (weight: 0.6055)\n",
      "  Block 55: Token 27 -> Expert 6 (weight: 0.3945)\n",
      "  Block 56: Token 28 -> Expert 2 (weight: 0.6284)\n",
      "  Block 57: Token 28 -> Expert 0 (weight: 0.3716)\n",
      "  Block 58: Token 29 -> Expert 2 (weight: 0.5223)\n",
      "  Block 59: Token 29 -> Expert 7 (weight: 0.4777)\n",
      "  Block 60: Token 30 -> Expert 2 (weight: 0.6220)\n",
      "  Block 61: Token 30 -> Expert 6 (weight: 0.3780)\n",
      "  Block 62: Token 31 -> Expert 1 (weight: 0.6257)\n",
      "  Block 63: Token 31 -> Expert 7 (weight: 0.3743)\n",
      "\n",
      "=== Tensor reshaping for kernel ===\n",
      "Original x_flat shape: torch.Size([32, 32])\n",
      "Need to permute/gather tokens according to active blocks...\n",
      "Active tokens shape: torch.Size([64, 32])\n",
      "First few active tokens:\n",
      "tensor([[-1.0840,  0.7476, -2.0949,  0.7977,  0.4719,  1.7606, -1.9649, -1.7086,\n",
      "          0.9946,  0.7740,  1.1468, -0.6849,  1.1711, -0.2889, -0.9564, -1.8661,\n",
      "         -0.6677, -1.0701, -0.5974, -0.0880,  0.8172, -0.6565,  0.9629, -0.1479,\n",
      "         -1.8780, -0.7205, -0.4407,  0.1059, -0.4681,  1.6739,  2.0291, -0.8474],\n",
      "        [-1.0840,  0.7476, -2.0949,  0.7977,  0.4719,  1.7606, -1.9649, -1.7086,\n",
      "          0.9946,  0.7740,  1.1468, -0.6849,  1.1711, -0.2889, -0.9564, -1.8661,\n",
      "         -0.6677, -1.0701, -0.5974, -0.0880,  0.8172, -0.6565,  0.9629, -0.1479,\n",
      "         -1.8780, -0.7205, -0.4407,  0.1059, -0.4681,  1.6739,  2.0291, -0.8474],\n",
      "        [-0.9731, -0.9436, -0.1568,  0.6413,  0.3129, -1.4161,  0.3308, -0.3108,\n",
      "          0.4737, -0.2979,  0.5771,  0.3594,  0.1896,  1.2535, -1.3884, -1.0415,\n",
      "         -0.7554, -0.2101,  2.2488,  0.8743, -0.4880, -0.2939, -0.8489,  0.6770,\n",
      "         -1.4020,  1.5661, -0.3299,  1.2191,  1.7621,  0.2109,  0.3132, -0.1830],\n",
      "        [-0.9731, -0.9436, -0.1568,  0.6413,  0.3129, -1.4161,  0.3308, -0.3108,\n",
      "          0.4737, -0.2979,  0.5771,  0.3594,  0.1896,  1.2535, -1.3884, -1.0415,\n",
      "         -0.7554, -0.2101,  2.2488,  0.8743, -0.4880, -0.2939, -0.8489,  0.6770,\n",
      "         -1.4020,  1.5661, -0.3299,  1.2191,  1.7621,  0.2109,  0.3132, -0.1830],\n",
      "        [ 2.4689, -1.4298, -0.5724,  1.7165, -1.5735,  0.4569,  0.9156,  1.0335,\n",
      "         -1.0671, -1.3350, -0.4827,  2.1701, -0.8565,  0.4870,  0.9237, -0.5237,\n",
      "          1.2502, -0.3172, -1.1296, -0.4376, -0.4122, -0.0655,  0.2831, -1.1703,\n",
      "          0.4122, -0.5798, -0.3756, -0.5615,  1.8547,  0.8539,  0.4536,  1.2710]])\n",
      "=== Summary for sdd_kernel call ===\n",
      "Strides:\n",
      "  stride_xm=32, stride_xk=1\n",
      "  stride_wk=1024, stride_wn=1\n",
      "  stride_om=1024, stride_on=1\n",
      "\n",
      "Kernel parameters:\n",
      "  x_ptr: active_tokens (shape: torch.Size([64, 32]))\n",
      "  w1_ptr: w1 (shape: torch.Size([32, 1024]))\n",
      "  output_ptr: sparse output tensor (need to create)\n",
      "  row_indices_ptr: torch.Size([64]) -> tensor([ 0,  0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,\n",
      "         9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17,\n",
      "        18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25, 25, 26, 26,\n",
      "        27, 27, 28, 28, 29, 29, 30, 30, 31, 31])\n",
      "  col_indices_ptr: torch.Size([64]) -> tensor([4, 6, 5, 7, 2, 0, 4, 5, 5, 6, 1, 5, 7, 2, 3, 5, 4, 6, 4, 3, 6, 1, 2, 3,\n",
      "        2, 0, 2, 5, 7, 2, 7, 2, 4, 3, 6, 0, 4, 0, 5, 3, 0, 5, 7, 3, 3, 4, 0, 1,\n",
      "        1, 5, 2, 7, 0, 4, 3, 6, 2, 0, 2, 7, 2, 6, 1, 7])\n",
      "  M=32\n",
      "  N=1024 (or maybe 256?)\n",
      "  K=32\n",
      "\n",
      "ðŸš§ TODO: Figure out the correct output tensor shape and how to handle sparsity!\n",
      "The current MoeMLP.forward() has incomplete tensor reshaping before the kernel call.\n",
      "\n",
      "Sparse output tensor shape: torch.Size([32, 1024])\n",
      "Most entries will be zero - only active expert blocks will be filled!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from einops import rearrange\n",
    "import math\n",
    "\n",
    "# Simple config for toy MoE testing\n",
    "@dataclass\n",
    "class ToyMoEConfig:\n",
    "    n_embd: int = 32          # small embedding dimension\n",
    "    num_experts: int = 8      # total number of experts\n",
    "    num_experts_per_tok: int = 2  # top-k active experts per token\n",
    "    norm_topk_prob: bool = True   # normalize top-k probabilities\n",
    "    bias: bool = True\n",
    "    dropout: float = 0.0\n",
    "\n",
    "config = ToyMoEConfig()\n",
    "print(f\"Config: {config}\")\n",
    "\n",
    "# Create toy input data\n",
    "batch_size = 4\n",
    "seq_len = 8  # small sequence length\n",
    "n_embd = config.n_embd\n",
    "\n",
    "# Input tensor: [batch_size, seq_len, n_embd]\n",
    "x = torch.randn(batch_size, seq_len, n_embd)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "# Flatten to [num_tokens, n_embd] as the MoeMLP expects\n",
    "x_flat = rearrange(x, 'batch seq hidden -> (batch seq) hidden')\n",
    "num_tokens = batch_size * seq_len\n",
    "print(f\"\\nFlattened input shape: {x_flat.shape}\")\n",
    "print(f\"num_tokens = {num_tokens}\")\n",
    "\n",
    "# Create a simplified router to understand the routing behavior\n",
    "router = nn.Linear(config.n_embd, config.num_experts, bias=False)\n",
    "\n",
    "# Get router logits and top-k selection\n",
    "router_logits = router(x_flat)\n",
    "print(f\"Router logits shape: {router_logits.shape}\")  # [num_tokens, num_experts]\n",
    "\n",
    "# Softmax and top-k selection\n",
    "router_weights = F.softmax(router_logits, dim=1, dtype=torch.float)\n",
    "router_weights, selected_experts = torch.topk(router_weights, config.num_experts_per_tok, dim=-1)\n",
    "\n",
    "if config.norm_topk_prob:\n",
    "    router_weights /= router_weights.sum(dim=-1, keepdim=True)\n",
    "\n",
    "print(f\"Router weights shape: {router_weights.shape}\")  # [num_tokens, top_k]\n",
    "print(f\"Selected experts shape: {selected_experts.shape}\")  # [num_tokens, top_k]\n",
    "print(f\"Selected experts:\\n{selected_experts}\")\n",
    "\n",
    "# Create expert mask to see which experts are active for each token\n",
    "expert_mask = F.one_hot(selected_experts, num_classes=config.num_experts)\n",
    "print(f\"Expert mask shape: {expert_mask.shape}\")  # [num_tokens, top_k, num_experts]\n",
    "\n",
    "# Rearrange as done in the original code: n k e -> e k n\n",
    "expert_mask_rearranged = rearrange(expert_mask, 'n k e -> e k n')\n",
    "print(f\"Rearranged expert mask shape: {expert_mask_rearranged.shape}\")  # [num_experts, top_k, num_tokens]\n",
    "\n",
    "# Create weight matrices as in the MoeMLP class\n",
    "w1 = torch.randn(config.n_embd, config.num_experts * 4 * config.n_embd) \n",
    "w2 = torch.randn(config.num_experts * 4 * config.n_embd, config.n_embd)\n",
    "\n",
    "print(f\"w1 shape: {w1.shape}\")  # [n_embd, num_experts * 4 * n_embd]\n",
    "print(f\"w2 shape: {w2.shape}\")  # [num_experts * 4 * n_embd, n_embd]\n",
    "\n",
    "# Show what the kernel call parameters should be:\n",
    "print(f\"\\n=== Parameters for sdd_kernel call ===\")\n",
    "print(f\"M (num_tokens): {num_tokens}\")\n",
    "print(f\"N (ffn_hidden * num_experts): {4 * config.n_embd * config.num_experts}\")  # This is wrong in the original code\n",
    "print(f\"K (hidden_size): {config.n_embd}\")\n",
    "\n",
    "# The issue: N should probably be related to num_experts_per_tok, not total experts\n",
    "print(f\"N (corrected, ffn_hidden * num_experts_per_tok): {4 * config.n_embd * config.num_experts_per_tok}\")\n",
    "\n",
    "# Count tokens per expert\n",
    "tokens_per_expert = torch.zeros(config.num_experts, dtype=torch.long)\n",
    "for expert_idx in range(config.num_experts):\n",
    "    # Count how many tokens are assigned to this expert\n",
    "    mask = (selected_experts == expert_idx).any(dim=1)\n",
    "    tokens_per_expert[expert_idx] = mask.sum()\n",
    "\n",
    "print(f\"\\nTokens per expert: {tokens_per_expert}\")\n",
    "print(f\"Total active assignments: {(selected_experts >= 0).sum()}\")  # should be num_tokens * num_experts_per_tok\n",
    "\n",
    "# Create the indices needed for sparse kernel call\n",
    "# We need to figure out which blocks are active and their positions\n",
    "\n",
    "print(\"=== Creating sparse indices for kernel ===\")\n",
    "\n",
    "# Create row and column indices for each active block\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "\n",
    "# Iterate through each token and its selected experts\n",
    "for token_idx in range(num_tokens):\n",
    "    for k_idx in range(config.num_experts_per_tok):\n",
    "        expert_idx = selected_experts[token_idx, k_idx]\n",
    "        \n",
    "        # Row index is the token index\n",
    "        row_indices.append(token_idx)\n",
    "        \n",
    "        # Column index is the expert index (which expert block)\n",
    "        col_indices.append(expert_idx.item())\n",
    "\n",
    "row_indices = torch.tensor(row_indices, dtype=torch.long)\n",
    "col_indices = torch.tensor(col_indices, dtype=torch.long)\n",
    "\n",
    "print(f\"Number of active blocks: {len(row_indices)}\")\n",
    "print(f\"Row indices (which token): {row_indices}\")\n",
    "print(f\"Col indices (which expert): {col_indices}\")\n",
    "\n",
    "# Show the mapping\n",
    "print(f\"\\nActive blocks mapping:\")\n",
    "for i in range(len(row_indices)):\n",
    "    token_idx = row_indices[i]\n",
    "    expert_idx = col_indices[i]\n",
    "    weight = router_weights.flatten()[i]  # corresponding weight\n",
    "    print(f\"  Block {i}: Token {token_idx} -> Expert {expert_idx} (weight: {weight:.4f})\")\n",
    "\n",
    "# This shows what tensor we need to create for the x_ptr in the kernel\n",
    "print(f\"\\n=== Tensor reshaping for kernel ===\")\n",
    "print(f\"Original x_flat shape: {x_flat.shape}\")\n",
    "print(f\"Need to permute/gather tokens according to active blocks...\")\n",
    "\n",
    "# Example of how to gather the active tokens\n",
    "active_tokens = x_flat[row_indices]  # Shape: [num_active_blocks, n_embd]\n",
    "print(f\"Active tokens shape: {active_tokens.shape}\")\n",
    "print(f\"First few active tokens:\\n{active_tokens[:5]}\")\n",
    "# Summary: What the kernel needs and stride calculations\n",
    "print(\"=== Summary for sdd_kernel call ===\")\n",
    "\n",
    "# Calculate strides for the matrices\n",
    "# x_ptr: active_tokens [num_active_blocks, n_embd]\n",
    "stride_xm = config.n_embd  # stride between rows\n",
    "stride_xk = 1              # stride between columns (contiguous)\n",
    "\n",
    "# w1_ptr: weight matrix [n_embd, num_experts * 4 * n_embd] \n",
    "stride_wk = config.num_experts * 4 * config.n_embd  # stride between rows\n",
    "stride_wn = 1                                        # stride between columns\n",
    "\n",
    "# output_ptr: sparse output [num_tokens, num_experts * 4 * n_embd]\n",
    "# But we only fill the active blocks!\n",
    "stride_om = config.num_experts * 4 * config.n_embd  # stride between rows  \n",
    "stride_on = 1                                        # stride between columns\n",
    "\n",
    "print(f\"Strides:\")\n",
    "print(f\"  stride_xm={stride_xm}, stride_xk={stride_xk}\")\n",
    "print(f\"  stride_wk={stride_wk}, stride_wn={stride_wn}\")\n",
    "print(f\"  stride_om={stride_om}, stride_on={stride_on}\")\n",
    "\n",
    "print(f\"\\nKernel parameters:\")\n",
    "print(f\"  x_ptr: active_tokens (shape: {active_tokens.shape})\")\n",
    "print(f\"  w1_ptr: w1 (shape: {w1.shape})\")\n",
    "print(f\"  output_ptr: sparse output tensor (need to create)\")\n",
    "print(f\"  row_indices_ptr: {row_indices.shape} -> {row_indices}\")  \n",
    "print(f\"  col_indices_ptr: {col_indices.shape} -> {col_indices}\")\n",
    "print(f\"  M={num_tokens}\")\n",
    "print(f\"  N={4 * config.n_embd * config.num_experts} (or maybe {4 * config.n_embd * config.num_experts_per_tok}?)\")\n",
    "print(f\"  K={config.n_embd}\")\n",
    "\n",
    "print(f\"\\nðŸš§ TODO: Figure out the correct output tensor shape and how to handle sparsity!\")\n",
    "print(f\"The current MoeMLP.forward() has incomplete tensor reshaping before the kernel call.\")\n",
    "\n",
    "# Create a placeholder sparse output tensor to show what it might look like\n",
    "sparse_output = torch.zeros(num_tokens, config.num_experts * 4 * config.n_embd)\n",
    "print(f\"\\nSparse output tensor shape: {sparse_output.shape}\")\n",
    "print(f\"Most entries will be zero - only active expert blocks will be filled!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
