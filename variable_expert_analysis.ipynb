{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Variable Expert Analysis - Unified Notebook\n",
    "\n",
    "This notebook supports analysis of MoE models with variable-sized experts across different model sizes and expert configurations.\n",
    "\n",
    "## Model Sizes\n",
    "\n",
    "### GPT-2 120M (`DATASET = \"gpt2\"`)\n",
    "- 12 layers, 768 dim, OpenWebText dataset\n",
    "- **5:1 ratio** (`EXPERT_CONFIG = \"5to1\"`): 4x2560 + 4x512 experts\n",
    "  - Available seeds: 42, 1223, 1337\n",
    "- **23:1 ratio** (`EXPERT_CONFIG = \"23to1\"`): 4x2944 + 4x128 experts\n",
    "  - Available seeds: 42, 1223, 1337\n",
    "\n",
    "### GPT-2 250M (`DATASET = \"gpt2_250m\"`)\n",
    "- 16 layers, 1024 dim, OpenWebText dataset (Chinchilla scaling)\n",
    "- **5:1 ratio** (`EXPERT_CONFIG = \"5to1\"`): 4x3456 + 4x640 experts\n",
    "  - Available seeds: 1337\n",
    "- **31:1 ratio** (`EXPERT_CONFIG = \"31to1\"`): 4x3968 + 4x128 experts\n",
    "  - Available seeds: 1337\n",
    "- **Uniform baseline** (`EXPERT_CONFIG = \"uniform\"`): 8x2048 experts\n",
    "  - Available seeds: 1337\n",
    "\n",
    "### WikiText (`DATASET = \"wikitext\"`)\n",
    "- 8 layers, 640 dim, WikiText dataset\n",
    "- Single configuration: 4x2432 + 4x128 experts\n",
    "\n",
    "## Usage\n",
    "\n",
    "Change the configuration variables at the top of the config cell:\n",
    "\n",
    "```python\n",
    "DATASET = \"gpt2\"          # Choose model size: \"gpt2\", \"gpt2_250m\", \"wikitext\"\n",
    "EXPERT_CONFIG = \"5to1\"    # Choose expert ratio: \"5to1\", \"23to1\", \"31to1\", \"uniform\"\n",
    "SEED = 1337               # Choose seed: 42, 1223, 1337 (check availability above)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict, Counter\nfrom tqdm import tqdm\nimport tiktoken\n\nfrom model import GPTConfig, MoeMLPWithTracking, GPTWithTracking\n\n\ntorch.backends.cuda.matmul.fp32_precision = 'tf32'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "# Change this to switch between model sizes and configurations\n",
    "DATASET = \"gpt2\"  # Options: \"gpt2\" (120M), \"gpt2_250m\" (250M), \"wikitext\"\n",
    "EXPERT_CONFIG = \"23to1\"  # Options: \"5to1\", \"23to1\", \"31to1\", \"uniform\" (depends on DATASET - see availability below)\n",
    "SEED = 42 # Options: 42, 1223, 1337 (depending on which are available)\n",
    "\n",
    "# Dataset-specific configurations\n",
    "CONFIGS = {\n",
    "    \"gpt2\": {\n",
    "        \"n_layer\": 12,\n",
    "        \"n_head\": 12,\n",
    "        \"n_embd\": 768,\n",
    "        \"vocab_size\": 50304,\n",
    "        \"val_data_path\": \"data/openwebtext/val.bin\",\n",
    "        \"expert_configs\": {\n",
    "            \"5to1\": {\n",
    "                \"expert_sizes\": [(4, 2560), (4, 512)],  # 5:1 ratio\n",
    "                \"base_dir\": \"gpt2_experiments/multiseed_5to1\",\n",
    "                \"run_name_pattern\": \"ratio5_lbl0.01_compute0.004_seed{seed}\",\n",
    "                \"model_name\": \"GPT-2 120M 5:1 (4x2560 + 4x512)\",\n",
    "                \"available_seeds\": [42, 1223, 1337]\n",
    "            },\n",
    "            \"23to1\": {\n",
    "                \"expert_sizes\": [(4, 2944), (4, 128)],  # 23:1 ratio\n",
    "                \"base_dir\": \"gpt2_experiments/multiseed_23to1\",\n",
    "                \"run_name_pattern\": \"ratio23_lbl0.01_compute0.004_seed{seed}\",\n",
    "                \"model_name\": \"GPT-2 120M 23:1 (4x2944 + 4x128)\",\n",
    "                \"available_seeds\": [42, 1223, 1337]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"gpt2_250m\": {\n",
    "        \"n_layer\": 16,\n",
    "        \"n_head\": 16,\n",
    "        \"n_embd\": 1024,\n",
    "        \"vocab_size\": 50304,\n",
    "        \"val_data_path\": \"data/openwebtext/val.bin\",\n",
    "        \"expert_configs\": {\n",
    "            \"5to1\": {\n",
    "                \"expert_sizes\": [(4, 3456), (4, 640)],  # 5:1 ratio\n",
    "                \"base_dir\": \"gpt2_250m_experiments/expert_sizes_final_weights\",\n",
    "                \"run_name_pattern\": \"sizes_5to1_lbl0.01_compute0.004_seed{seed}\",\n",
    "                \"model_name\": \"GPT-2 250M 5:1 (4x3456 + 4x640)\",\n",
    "                \"available_seeds\": [1337]\n",
    "            },\n",
    "            \"31to1\": {\n",
    "                \"expert_sizes\": [(4, 3968), (4, 128)],  # 31:1 ratio\n",
    "                \"base_dir\": \"gpt2_250m_experiments/expert_sizes_final_weights\",\n",
    "                \"run_name_pattern\": \"sizes_31to1_lbl0.01_compute0.004_seed{seed}\",\n",
    "                \"model_name\": \"GPT-2 250M 31:1 (4x3968 + 4x128)\",\n",
    "                \"available_seeds\": [1337]\n",
    "            },\n",
    "            \"uniform\": {\n",
    "                \"expert_sizes\": [(8, 2048)],  # 1:1 baseline\n",
    "                \"base_dir\": \"gpt2_250m_experiments/expert_sizes_final_weights\",\n",
    "                \"run_name_pattern\": \"sizes_uniform_lbl0.01_compute0.004_seed{seed}\",\n",
    "                \"model_name\": \"GPT-2 250M Uniform (8x2048)\",\n",
    "                \"available_seeds\": [1337]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"wikitext\": {\n",
    "        \"n_layer\": 8,\n",
    "        \"n_head\": 8,\n",
    "        \"n_embd\": 640,\n",
    "        \"vocab_size\": 8192,\n",
    "        \"expert_sizes\": [(4, 2432), (4, 128)],\n",
    "        \"checkpoint_dir\": f\"out-wikitext/moe-8x2-variable-4x2432-4x128-seed{SEED}\",\n",
    "        \"val_data_path\": \"data/wikitext/val.bin\",\n",
    "        \"model_name\": f\"WikiText (4x2432 + 4x128) seed{SEED}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build configuration based on DATASET\n",
    "if DATASET in [\"gpt2\", \"gpt2_250m\"]:\n",
    "    base_cfg = CONFIGS[DATASET]\n",
    "    expert_cfg = base_cfg[\"expert_configs\"][EXPERT_CONFIG]\n",
    "    \n",
    "    # Check if seed is available\n",
    "    if SEED not in expert_cfg[\"available_seeds\"]:\n",
    "        print(f\"WARNING: Seed {SEED} not available for {DATASET} {EXPERT_CONFIG}\")\n",
    "        print(f\"Available seeds: {expert_cfg['available_seeds']}\")\n",
    "    \n",
    "    # Build run name with seed\n",
    "    if \"{seed}\" in expert_cfg[\"run_name_pattern\"]:\n",
    "        run_name = expert_cfg[\"run_name_pattern\"].replace(\"{seed}\", str(SEED))\n",
    "    else:\n",
    "        run_name = expert_cfg[\"run_name_pattern\"]\n",
    "    \n",
    "    cfg = {\n",
    "        \"n_layer\": base_cfg[\"n_layer\"],\n",
    "        \"n_head\": base_cfg[\"n_head\"],\n",
    "        \"n_embd\": base_cfg[\"n_embd\"],\n",
    "        \"vocab_size\": base_cfg[\"vocab_size\"],\n",
    "        \"expert_sizes\": expert_cfg[\"expert_sizes\"],\n",
    "        \"checkpoint_dir\": f\"{expert_cfg['base_dir']}/{run_name}\",\n",
    "        \"val_data_path\": base_cfg[\"val_data_path\"],\n",
    "        \"model_name\": f\"{expert_cfg['model_name']} seed{SEED}\"\n",
    "    }\n",
    "else:\n",
    "    # Flat config (e.g., wikitext)\n",
    "    cfg = CONFIGS[DATASET]\n",
    "\n",
    "# Create model config\n",
    "config = GPTConfig(\n",
    "    n_layer = cfg['n_layer'],\n",
    "    n_head = cfg['n_head'],\n",
    "    n_embd = cfg['n_embd'],\n",
    "    bias = False,\n",
    "    vocab_size= cfg['vocab_size'],\n",
    "    \n",
    "    # MoE configuration with VARIABLE-SIZE EXPERTS\n",
    "    use_moe = True,\n",
    "    num_experts = 8,\n",
    "    num_experts_per_tok = 2,\n",
    "    norm_topk_prob = True,\n",
    "    block_size = 128,\n",
    "    block_k = 64,\n",
    "    expert_sizes = cfg[\"expert_sizes\"]\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Configuration: {cfg['model_name']}\")\n",
    "print(f\"Expert sizes: {config.expert_sizes}\")\n",
    "print(f\"Checkpoint: {cfg['checkpoint_dir']}/ckpt.pt\")\n",
    "print(f\"Val data: {cfg['val_data_path']}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-model",
   "metadata": {},
   "source": [
    "## Load Model and Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f\"{cfg['checkpoint_dir']}/ckpt.pt\"\n",
    "\n",
    "model = GPTWithTracking(config).to(torch.bfloat16)\n",
    "\n",
    "for block in model.transformer.h:\n",
    "    if hasattr(block.mlp, 'expert_sizes'):\n",
    "        old_mlp = block.mlp\n",
    "        block.mlp = MoeMLPWithTracking(config).to(torch.bfloat16)\n",
    "        block.mlp.load_state_dict(old_mlp.state_dict())\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "state_dict = checkpoint['model']\n",
    "if any(k.startswith('_orig_mod.') for k in state_dict.keys()):\n",
    "    state_dict = {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "print(f\"✓ Loaded checkpoint from {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-stats",
   "metadata": {},
   "source": [
    "## Collect ALL Routing Statistics in a SINGLE Pass\n",
    "\n",
    "This cell collects all statistics (individual expert assignments and combinations) in one efficient pass through the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-pass",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "val_data_path = cfg['val_data_path']\n",
    "val_data = np.memmap(val_data_path, dtype=np.uint16, mode='r')\n",
    "\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "num_layers = config.n_layer\n",
    "expert_sizes = model.transformer.h[0].mlp.expert_sizes\n",
    "\n",
    "# Initialize ALL tracking structures\n",
    "token_stats_per_layer = {}\n",
    "token_combinations_per_layer = {}\n",
    "\n",
    "for layer_idx in range(num_layers):\n",
    "    layer_name = f'layer_{layer_idx}'\n",
    "    token_stats_per_layer[layer_name] = defaultdict(lambda: {\n",
    "        'expert_counts': np.zeros(config.num_experts, dtype=np.int64),\n",
    "        'total_occurrences': 0,\n",
    "        'total_entropy': 0.0,\n",
    "        'total_layer_entropy': 0.0,\n",
    "        'expert_size_sum': 0.0,\n",
    "    })\n",
    "    token_combinations_per_layer[layer_name] = defaultdict(Counter)\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 1024\n",
    "total_tokens = len(val_data)\n",
    "num_batches = total_tokens // seq_len\n",
    "\n",
    "print(f\"Running single pass through {num_batches} batches to collect all statistics...\")\n",
    "\n",
    "for batch_idx in tqdm(range(num_batches)):\n",
    "    start_idx = batch_idx * seq_len\n",
    "    end_idx = start_idx + seq_len\n",
    "    batch_tokens = torch.from_numpy(val_data[start_idx:end_idx].astype(np.int64)).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        logits, loss, aux_loss = model(batch_tokens, targets=batch_tokens)\n",
    "\n",
    "    output_probs = F.softmax(logits[0], dim=-1)\n",
    "    epsilon = 1e-10\n",
    "    output_entropy = -(output_probs * torch.log(output_probs + epsilon)).sum(dim=-1).float().cpu().numpy()\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        layer_name = f'layer_{layer_idx}'\n",
    "        layer_assignments = aux_loss['expert_assignments'][layer_name][0].cpu().numpy()\n",
    "        layer_entropies = aux_loss['layer_entropies'][layer_name][0].cpu().numpy()\n",
    "        token_stats = token_stats_per_layer[layer_name]\n",
    "\n",
    "        for pos in range(seq_len):\n",
    "            token_id = int(batch_tokens[0, pos].item())\n",
    "            expert_ids = layer_assignments[pos]\n",
    "\n",
    "            # Update individual expert statistics\n",
    "            token_stats[token_id]['total_occurrences'] += 1\n",
    "            token_stats[token_id]['total_entropy'] += output_entropy[pos]\n",
    "            token_stats[token_id]['total_layer_entropy'] += layer_entropies[pos]\n",
    "\n",
    "            for expert_id in expert_ids:\n",
    "                token_stats[token_id]['expert_counts'][expert_id] += 1\n",
    "                token_stats[token_id]['expert_size_sum'] += expert_sizes[expert_id]\n",
    "\n",
    "            # Track expert combinations\n",
    "            expert_combination = tuple(sorted(expert_ids))\n",
    "            token_combinations_per_layer[layer_name][token_id][expert_combination] += 1\n",
    "\n",
    "print(f\"\\n✓ Collected all statistics in a single pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis",
   "metadata": {},
   "source": [
    "## Analysis: Print the Most Common Expert Combination for Each Token\n",
    "\n",
    "This shows which expert pair each token uses most frequently across all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "print-combinations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_expert_combo(combo, expert_sizes):\n",
    "    \"\"\"Format expert combination with sizes\"\"\"\n",
    "    return \",\".join([f\"{e}({expert_sizes[e]})\" for e in combo])\n",
    "\n",
    "def print_token_routing_table(token_combinations_per_layer, token_stats_per_layer, expert_sizes, tokenizer, max_tokens=100):\n",
    "    \"\"\"Print comprehensive routing table\"\"\"\n",
    "    \n",
    "    # Calculate average expert size and FLOPs for each token\n",
    "    token_avg_sizes = {}\n",
    "    for layer_name in token_stats_per_layer:\n",
    "        for token_id, stats in token_stats_per_layer[layer_name].items():\n",
    "            if stats['total_occurrences'] > 0:\n",
    "                avg_size = stats['expert_size_sum'] / (stats['total_occurrences'] * 2)  # 2 experts per token\n",
    "                if token_id not in token_avg_sizes:\n",
    "                    token_avg_sizes[token_id] = []\n",
    "                token_avg_sizes[token_id].append(avg_size)\n",
    "    \n",
    "    overall_avg_sizes = {tid: np.mean(sizes) for tid, sizes in token_avg_sizes.items()}\n",
    "    \n",
    "    # Header\n",
    "    print(f\"\\n{'='*200}\")\n",
    "    header = f\"{'Token ID':<10}{'Token':<20}{'Avg Size':<13}{'FLOPs':<16}\"\n",
    "    for layer_idx in range(num_layers):\n",
    "        header += f\"{'Layer ' + str(layer_idx):<21}\"\n",
    "    print(header)\n",
    "    print(f\"{'='*200}\")\n",
    "    \n",
    "    # Print first N tokens\n",
    "    for token_id in sorted(overall_avg_sizes.keys())[:max_tokens]:\n",
    "        try:\n",
    "            token_str = tokenizer.decode([token_id]).replace('\\n', '\\\\n')\n",
    "        except:\n",
    "            token_str = f\"<{token_id}>\"\n",
    "        \n",
    "        avg_size = overall_avg_sizes[token_id]\n",
    "        # FLOPs calculation: 2 * seq_len * hidden * expert_size (for matrix mult)\n",
    "        # Simplified: avg_size * hidden * 2 operations\n",
    "        flops = avg_size * config.n_embd * 4 * config.n_layer  # 4x forward/backward\n",
    "        \n",
    "        row = f\"{token_id:<10}{token_str:<20}{avg_size:<13.1f}{flops:<16,.0f}\"\n",
    "        \n",
    "        for layer_idx in range(num_layers):\n",
    "            layer_name = f'layer_{layer_idx}'\n",
    "            if token_id in token_combinations_per_layer[layer_name]:\n",
    "                combos = token_combinations_per_layer[layer_name][token_id]\n",
    "                most_common = combos.most_common(1)[0][0]\n",
    "                combo_str = f\"({format_expert_combo(most_common, expert_sizes)})\"\n",
    "                row += f\"{combo_str:<21}\"\n",
    "            else:\n",
    "                row += f\"{'N/A':<21}\"\n",
    "        \n",
    "        print(row)\n",
    "\n",
    "print_token_routing_table(token_combinations_per_layer, token_stats_per_layer, expert_sizes, tokenizer, max_tokens=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Building dataframe from collected statistics...\")\n",
    "\n",
    "# Get unique tokens\n",
    "all_token_ids = set()\n",
    "for layer_combos in token_combinations_per_layer.values():\n",
    "    all_token_ids.update(layer_combos.keys())\n",
    "\n",
    "# Build data for dataframe\n",
    "data = []\n",
    "for token_id in all_token_ids:\n",
    "    # Decode token\n",
    "    try:\n",
    "        token_text = tokenizer.decode([token_id])\n",
    "        token_text = token_text.replace('\\n', '\\\\n').replace('\\t', '\\\\t').replace('\\r', '\\\\r')\n",
    "        if '�' in token_text or not token_text.isprintable():\n",
    "            token_text = f\"<{token_id}>\"\n",
    "        if len(token_text) > 18:\n",
    "            token_text = token_text[:17] + '…'\n",
    "    except:\n",
    "        token_text = f\"<{token_id}>\"\n",
    "    \n",
    "    # Calculate average expert SIZE and ENTROPY across all layers\n",
    "    total_size = 0\n",
    "    total_entropy = 0.0\n",
    "    layer_count = 0\n",
    "    layer_data = {}\n",
    "    layer_entropy_data = {}\n",
    "    token_count = 0  # Track total occurrences of this token\n",
    "    \n",
    "    for layer_idx in range(num_layers):\n",
    "        layer_name = f'layer_{layer_idx}'\n",
    "        combos = token_combinations_per_layer[layer_name][token_id]\n",
    "        stats = token_stats_per_layer[layer_name][token_id]\n",
    "        \n",
    "        # Get token count from the first layer (all layers have same count)\n",
    "        if layer_idx == 0 and stats['total_occurrences'] > 0:\n",
    "            token_count = stats['total_occurrences']\n",
    "        \n",
    "        if combos:\n",
    "            most_common = combos.most_common(1)[0][0]\n",
    "            layer_size = sum(expert_sizes[e] for e in most_common)\n",
    "            total_size += layer_size\n",
    "            \n",
    "            # Calculate average entropy for this token in this layer\n",
    "            if stats['total_occurrences'] > 0:\n",
    "                layer_entropy = stats['total_entropy'] / stats['total_occurrences']\n",
    "                total_entropy += layer_entropy\n",
    "                \n",
    "                # Store layer-wise intermediate entropy\n",
    "                layer_wise_entropy = stats['total_layer_entropy'] / stats['total_occurrences']\n",
    "                layer_entropy_data[f'layer_{layer_idx}_entropy'] = layer_wise_entropy\n",
    "            \n",
    "            layer_count += 1\n",
    "            # Format with expert sizes: (5(128),7(128))\n",
    "            formatted = \"(\" + \",\".join([f\"{e}({expert_sizes[e]})\" for e in most_common]) + \")\"\n",
    "            layer_data[f'layer_{layer_idx}'] = formatted\n",
    "        else:\n",
    "            layer_data[f'layer_{layer_idx}'] = 'N/A'\n",
    "            layer_entropy_data[f'layer_{layer_idx}_entropy'] = np.nan\n",
    "    \n",
    "    avg_size = total_size / layer_count if layer_count > 0 else 0\n",
    "    avg_entropy = total_entropy / layer_count if layer_count > 0 else 0\n",
    "    flops = 4 * config.n_embd * total_size\n",
    "    \n",
    "    row = {\n",
    "        'token_id': token_id,\n",
    "        'token': token_text,\n",
    "        'count': token_count,\n",
    "        'avg_size': avg_size,\n",
    "        'avg_entropy': avg_entropy,\n",
    "        'flops': flops,\n",
    "        **layer_data,\n",
    "        **layer_entropy_data\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "# Create DataFrame and sort by FLOPs\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values('flops', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Calculate weighted FLOPs based on token frequency\n",
    "total_dataset_flops = (df['flops'] * df['count']).sum()\n",
    "total_tokens = df['count'].sum()\n",
    "weighted_avg_flops = total_dataset_flops / total_tokens\n",
    "\n",
    "print(f\"\\nDataFrame created with {len(df)} tokens, sorted by FLOPs (low to high)\")\n",
    "print(f\"\\nFirst 20 rows (lowest FLOPs):\")\n",
    "# Select a subset of columns for display\n",
    "display_cols = ['token_id', 'token', 'count', 'avg_size', 'avg_entropy', 'flops', \n",
    "                'layer_0_entropy', 'layer_5_entropy', 'layer_11_entropy']\n",
    "print(df[display_cols].head(20).to_string())\n",
    "\n",
    "print(f\"\\n\\nLast 20 rows (highest FLOPs):\")\n",
    "print(df[display_cols].tail(20).to_string())\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Summary Statistics:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total unique tokens: {len(df)}\")\n",
    "print(f\"Total token occurrences: {total_tokens:,}\")\n",
    "\n",
    "print(f\"\\nToken Count distribution:\")\n",
    "print(f\"  Min:    {df['count'].min():,}\")\n",
    "print(f\"  25%:    {df['count'].quantile(0.25):,.0f}\")\n",
    "print(f\"  Median: {df['count'].median():,.0f}\")\n",
    "print(f\"  75%:    {df['count'].quantile(0.75):,.0f}\")\n",
    "print(f\"  Max:    {df['count'].max():,}\")\n",
    "print(f\"  Mean:   {df['count'].mean():,.0f}\")\n",
    "\n",
    "print(f\"\\nFLOPs distribution:\")\n",
    "print(f\"  Min:    {df['flops'].min():,.0f}\")\n",
    "print(f\"  25%:    {df['flops'].quantile(0.25):,.0f}\")\n",
    "print(f\"  Median: {df['flops'].median():,.0f}\")\n",
    "print(f\"  75%:    {df['flops'].quantile(0.75):,.0f}\")\n",
    "print(f\"  Max:    {df['flops'].max():,.0f}\")\n",
    "print(f\"  Mean:   {df['flops'].mean():,.0f}\")\n",
    "\n",
    "print(f\"\\nAverage Size distribution:\")\n",
    "print(f\"  Tokens with avg_size >= {4*config.n_embd}: {(df['avg_size'] >= 4*config.n_embd).sum()} ({100*(df['avg_size'] >= config.n_embd).sum()/len(df):.2f}%)\")\n",
    "print(f\"  Tokens with avg_size < {4*config.n_embd}:  {(df['avg_size'] < 4*config.n_embd).sum()} ({100*(df['avg_size'] < 4*config.n_embd).sum()/len(df):.2f}%)\")\n",
    "\n",
    "print(f\"\\nAverage Output Entropy distribution:\")\n",
    "print(f\"  Min:    {df['avg_entropy'].min():.4f}\")\n",
    "print(f\"  25%:    {df['avg_entropy'].quantile(0.25):.4f}\")\n",
    "print(f\"  Median: {df['avg_entropy'].median():.4f}\")\n",
    "print(f\"  75%:    {df['avg_entropy'].quantile(0.75):.4f}\")\n",
    "print(f\"  Max:    {df['avg_entropy'].max():.4f}\")\n",
    "print(f\"  Mean:   {df['avg_entropy'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nLayer-wise Entropy Statistics:\")\n",
    "for layer_idx in [0, num_layers//2, num_layers-1]:\n",
    "    layer_col = f'layer_{layer_idx}_entropy'\n",
    "    print(f\"  Layer {layer_idx}:\")\n",
    "    print(f\"    Mean:   {df[layer_col].mean():.4f}\")\n",
    "    print(f\"    Median: {df[layer_col].median():.4f}\")\n",
    "    print(f\"    Std:    {df[layer_col].std():.4f}\")\n",
    "\n",
    "baseline_flops = config.n_layer * 4 * config.n_embd * (config.n_embd*4)  # num_layers * 4 * hidden_size * total expert_size\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FLOPs Analysis:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Average FLOPs per unique token: {df['flops'].mean():.0f} ({100*df['flops'].mean()/baseline_flops:.2f}% of baseline)\")\n",
    "print(f\"Weighted average FLOPs per token occurrence: {weighted_avg_flops:.0f} ({100*weighted_avg_flops/baseline_flops:.2f}% of baseline)\")\n",
    "print(f\"Total dataset FLOPs: {total_dataset_flops:,.0f}\")\n",
    "print(f\"Baseline total FLOPs: {baseline_flops * total_tokens:,.0f}\")\n",
    "print(f\"FLOPs savings: {100 * (1 - total_dataset_flops / (baseline_flops * total_tokens)):.2f}%\")\n",
    "\n",
    "# Store the dataframe for further analysis\n",
    "expert_combinations_df = df\n",
    "sweep_value = '-'.join(checkpoint_path.split('-')).split('/')[-2]\n",
    "\n",
    "df.to_csv(f'analysis_csvs/{sweep_value}_expert_combinations.csv', index=False)\n",
    "print(f\"\\n✓ Saved to analysis_csvs/{sweep_value}_expert_combinations.csv\")\n",
    "print(f\"  Columns: {', '.join(df.columns.tolist()[:10])}... (and {len(df.columns)-10} more)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-token statistics FOR EACH LAYER\n",
    "for layer_idx in range(num_layers):\n",
    "    layer_name = f'layer_{layer_idx}'\n",
    "    token_stats = token_stats_per_layer[layer_name]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"LAYER {layer_idx} ANALYSIS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Compute derived metrics for each token\n",
    "    token_analysis = {}\n",
    "    \n",
    "    for token_id, stats in token_stats.items():\n",
    "        if stats['total_occurrences'] > 0:\n",
    "            # Average entropy\n",
    "            avg_entropy = stats['total_entropy'] / stats['total_occurrences']\n",
    "            \n",
    "            # Expert distribution (normalized)\n",
    "            expert_distribution = stats['expert_counts'] / stats['expert_counts'].sum()\n",
    "            \n",
    "            # Most common expert\n",
    "            most_common_expert = np.argmax(stats['expert_counts'])\n",
    "            \n",
    "            # Average expert size\n",
    "            avg_expert_size = stats['expert_size_sum'] / stats['expert_counts'].sum()\n",
    "            \n",
    "            token_analysis[token_id] = {\n",
    "                'avg_entropy': avg_entropy,\n",
    "                'occurrences': stats['total_occurrences'],\n",
    "                'expert_distribution': expert_distribution,\n",
    "                'most_common_expert': most_common_expert,\n",
    "                'avg_expert_size': avg_expert_size,\n",
    "            }\n",
    "    \n",
    "    # Plot distribution of average expert sizes\n",
    "    all_expert_sizes = np.array([a['avg_expert_size'] for a in token_analysis.values()])\n",
    "    all_occurrences = np.array([a['occurrences'] for a in token_analysis.values()])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Layer {layer_idx} Token Routing Analysis', fontsize=16)\n",
    "    \n",
    "    # Unweighted histogram (by unique tokens)\n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(all_expert_sizes, bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax1.axvline(x=config.expert_sizes[1][1], color='blue', linestyle='--', label=f'Small ({config.expert_sizes[1][1]})', linewidth=2)\n",
    "    ax1.axvline(x=config.expert_sizes[0][1], color='red', linestyle='--', label=f'Large ({config.expert_sizes[0][1]})', linewidth=2)\n",
    "    ax1.axvline(x=np.mean(all_expert_sizes), color='green', linestyle='--', label=f'Mean ({np.mean(all_expert_sizes):.0f})', linewidth=2)\n",
    "    ax1.set_xlabel('Average Expert Size per Token')\n",
    "    ax1.set_ylabel('Number of Unique Tokens')\n",
    "    ax1.set_title('Distribution by Unique Tokens (Unweighted)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Weighted histogram (by token occurrences)\n",
    "    ax2 = axes[1]\n",
    "    ax2.hist(all_expert_sizes, bins=50, weights=all_occurrences, alpha=0.7, edgecolor='black', color='orange')\n",
    "    ax2.axvline(x=config.expert_sizes[1][1], color='blue', linestyle='--', label=f'Small ({config.expert_sizes[1][1]})', linewidth=2)\n",
    "    ax2.axvline(x=config.expert_sizes[0][1], color='red', linestyle='--', label=f'Large ({config.expert_sizes[0][1]})', linewidth=2)\n",
    "    weighted_mean = np.average(all_expert_sizes, weights=all_occurrences)\n",
    "    ax2.axvline(x=weighted_mean, color='green', linestyle='--', label=f'Weighted Mean ({weighted_mean:.0f})', linewidth=2)\n",
    "    ax2.set_xlabel('Average Expert Size per Token')\n",
    "    ax2.set_ylabel('Total Token Occurrences')\n",
    "    ax2.set_title('Distribution by Token Occurrences (Weighted)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Pie chart - weighted breakdown\n",
    "    ax3 = axes[2]\n",
    "    large_expert_occurrences = sum(all_occurrences[all_expert_sizes > (config.n_embd * 4)/2])\n",
    "    small_expert_occurrences = sum(all_occurrences[all_expert_sizes <= (config.n_embd * 4)/2])\n",
    "    total_occurrences = large_expert_occurrences + small_expert_occurrences\n",
    "    \n",
    "    ax3.pie([large_expert_occurrences, small_expert_occurrences],\n",
    "            labels=[f'Large experts\\n(>{(config.n_embd * 4)/2})', f'Small experts\\n(≤{(config.n_embd * 4)/2})'],\n",
    "            autopct='%1.1f%%',\n",
    "            colors=['red', 'blue'])\n",
    "    ax3.set_title(f'Token Occurrences by Expert Size\\n(Total: {total_occurrences:,} tokens)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"Average Expert Size Statistics (Unweighted):\")\n",
    "    print(f\"  Mean: {np.mean(all_expert_sizes):.2f}\")\n",
    "    print(f\"  Median: {np.median(all_expert_sizes):.2f}\")\n",
    "    print(f\"  Std: {np.std(all_expert_sizes):.2f}\")\n",
    "    \n",
    "    print(f\"\\nAverage Expert Size Statistics (Weighted by occurrences):\")\n",
    "    print(f\"  Weighted Mean: {weighted_mean:.2f}\")\n",
    "    \n",
    "    # Count how many tokens go to mostly large vs mostly small experts\n",
    "    large_expert_tokens = sum(1 for s in all_expert_sizes if s > (config.n_embd * 4)/2)\n",
    "    small_expert_tokens = sum(1 for s in all_expert_sizes if s <= (config.n_embd * 4)/2)\n",
    "    print(f\"\\nUnique Token routing breakdown:\")\n",
    "    print(f\"  Unique tokens routing mostly to LARGE experts: {large_expert_tokens} ({100*large_expert_tokens/len(all_expert_sizes):.1f}%)\")\n",
    "    print(f\"  Unique tokens routing mostly to SMALL experts: {small_expert_tokens} ({100*small_expert_tokens/len(all_expert_sizes):.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nWeighted by occurrences:\")\n",
    "    print(f\"  Token occurrences routed to LARGE experts: {large_expert_occurrences:,} ({100*large_expert_occurrences/total_occurrences:.1f}%)\")\n",
    "    print(f\"  Token occurrences routed to SMALL experts: {small_expert_occurrences:,} ({100*small_expert_occurrences/total_occurrences:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY ACROSS ALL LAYERS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract the ratio from EXPERT_CONFIG (e.g., \"5to1\" -> 5, \"23to1\" -> 23)\n",
    "# ratio = int(EXPERT_CONFIG.split('to')[0]) sure, we can use this\n",
    "ratio = 23 #or 5\n",
    "\n",
    "dfs = {}\n",
    "for seed in [42, 1223, 1337]:\n",
    "    '''UNCOMMENT ME TO USE, MAKE SURE TO MATCH'''\n",
    "    # sweep_value = f\"ratio23_lbl0.01_compute0.004_seed{seed}\"\n",
    "    # sweep_value = f\"ratio5_lbl0.01_compute0.004_seed{seed}\"\n",
    "    # sweep_value = f\"ratio5_lbl0.08_compute0.004_seed{seed}\"\n",
    "    sweep_value = f\"ratio23_lbl0.08_compute0.004_seed{seed}\"\n",
    "    dfs[seed] = pd.read_csv(f'analysis_csvs/{sweep_value}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b110ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Merge all three seeds\n",
    "df = dfs[42].merge(dfs[1223], on='token', suffixes=('_42', '_1223'))\n",
    "df = df.merge(dfs[1337], on='token')\n",
    "df = df.rename(columns={'avg_size': 'avg_size_1337'})\n",
    "\n",
    "# Calculate range (max - min) across all three seeds\n",
    "df['max_size'] = df[['avg_size_42', 'avg_size_1223', 'avg_size_1337']].max(axis=1)\n",
    "df['min_size'] = df[['avg_size_42', 'avg_size_1223', 'avg_size_1337']].min(axis=1)\n",
    "df['range'] = df['max_size'] - df['min_size']\n",
    "df['mean_size'] = df[['avg_size_42', 'avg_size_1223', 'avg_size_1337']].mean(axis=1)\n",
    "\n",
    "# Use ratio to calculate bucket thresholds (scale from baseline of ratio=5)\n",
    "# For ratio=5: tight=235, medium=470, wide=705\n",
    "# Scale proportionally for other ratios\n",
    "tight_threshold = 235\n",
    "medium_threshold = 470\n",
    "wide_threshold = 705\n",
    "\n",
    "# Create different bucket sizes\n",
    "df['all_exact'] = (\n",
    "    np.isclose(df['avg_size_42'], df['avg_size_1223']) & \n",
    "    np.isclose(df['avg_size_1223'], df['avg_size_1337'])\n",
    ")\n",
    "exact_bucket = df[df['all_exact']].copy()\n",
    "tight_bucket = df[df['range'] <= tight_threshold].copy()\n",
    "medium_bucket = df[df['range'] <= medium_threshold].copy()\n",
    "wide_bucket = df[df['range'] <= wide_threshold].copy()\n",
    "\n",
    "print(f\"Using ratio: {ratio}\")\n",
    "print(f\"Bucket thresholds: tight={tight_threshold:.0f}, medium={medium_threshold:.0f}, wide={wide_threshold:.0f}\\n\")\n",
    "\n",
    "print(f\"Exact bucket:                {len(exact_bucket):,} tokens ({100*len(exact_bucket)/len(df):.1f}%)\")\n",
    "print(f\"Tight bucket (±{tight_threshold:.0f}):  {len(tight_bucket):,} tokens ({100*len(tight_bucket)/len(df):.1f}%)\")\n",
    "print(f\"Medium bucket (±{medium_threshold:.0f}): {len(medium_bucket):,} tokens ({100*len(medium_bucket)/len(df):.1f}%)\")\n",
    "print(f\"Wide bucket (±{wide_threshold:.0f}):   {len(wide_bucket):,} tokens ({100*len(wide_bucket)/len(df):.1f}%)\")\n",
    "\n",
    "# Save to CSV with ratio-based filenames\n",
    "exact_bucket.to_csv(f'analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_exact.csv', index=False)\n",
    "tight_bucket.to_csv(f'analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_{tight_threshold:.0f}.csv', index=False)\n",
    "medium_bucket.to_csv(f'analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_{medium_threshold:.0f}.csv', index=False)\n",
    "wide_bucket.to_csv(f'analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_{wide_threshold:.0f}.csv', index=False)\n",
    "\n",
    "print(\"\\nSaved buckets to:\")\n",
    "print(f\"  - analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_exact.csv\")\n",
    "print(f\"  - analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_{tight_threshold:.0f}.csv\")\n",
    "print(f\"  - analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_{medium_threshold:.0f}.csv\")\n",
    "print(f\"  - analysis_csvs/owt_same_avg_size_tokens_ratio{ratio}_bucket_{wide_threshold:.0f}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c11816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vanilla = pd.read_csv('analysis_csvs/moe-8x2-8x1536_expert_combinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd635c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_bucket_deduped = exact_bucket.drop_duplicates(subset='token')\n",
    "df_vanilla_deduped = df_vanilla.drop_duplicates(subset='token')\n",
    "\n",
    "result = exact_bucket_deduped.merge(df_vanilla_deduped, on='token', suffixes=('_exact', '_vanilla'))\n",
    "result.to_csv('analysis_csvs/owt_same_avg_size_tokens_bucket_exact_vs_vanilla.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('analysis_csvs/variable_experts_gpt2_data.csv')\n",
    "\n",
    "df.plot(x='avg expert size', y='val/ce_loss', kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf915f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('analysis_csvs/variable_experts_gpt2_data.csv')\n",
    "\n",
    "# Create ratio labels manually based on the expert sizes\n",
    "ratio_map = {\n",
    "    'Baseline': '1:1',\n",
    "    '2560x512': '5:1',\n",
    "    '2688x384': '7:1',\n",
    "    '2816x256': '11:1',\n",
    "    '2944x128': '23:1'\n",
    "}\n",
    "df['ratio_label'] = df['Name'].map(ratio_map)\n",
    "\n",
    "# Create numeric ratio for sorting/coloring\n",
    "ratio_numeric = {\n",
    "    'Baseline': 1,\n",
    "    '2560x512': 5,\n",
    "    '2688x384': 7,\n",
    "    '2816x256': 11,\n",
    "    '2944x128': 23\n",
    "}\n",
    "df['ratio'] = df['Name'].map(ratio_numeric)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "ax.scatter(df['avg expert size'], df['val/ce_loss'], \n",
    "           c=df['ratio'], s=150, alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    ax.annotate(row['ratio_label'], \n",
    "                (row['avg expert size'], row['val/ce_loss']),\n",
    "                xytext=(8, 8), textcoords='offset points',\n",
    "                fontsize=11, fontweight='bold')\n",
    "\n",
    "\n",
    "baseline_loss = df[df['Name'] == 'Baseline']['val/ce_loss'].values[0]\n",
    "baseline_params = df[df['Name'] == 'Baseline']['avg expert size'].values[0]\n",
    "ax.axhline(baseline_loss, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax.text(1500, baseline_loss + 0.002, 'Baseline', \n",
    "        ha='right', va='bottom', fontsize=9, color='gray')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Average Active Parameters per Token', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Validation Loss', fontsize=12, fontweight='bold')\n",
    "ax.set_title('MoE Efficiency: Loss vs Active Parameters', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(True, alpha=0.3, linestyle=':', linewidth=0.5)\n",
    "ax.set_ylim(3.22, 3.31)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('loss_vs_active_params.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e41d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#work on correlations between size and token count, entropy, etc.\n",
    "import pandas as pd\n",
    "ratio_5_exact = pd.read_csv('analysis_csvs/owt_same_avg_size_tokens_ratio5_bucket_exact_trimmed.csv')\n",
    "# ratio_23_exact = pd.read_csv('analysis_csvs/owt_same_avg_size_tokens_ratio23_bucket_exact_trimmed.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2da5f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio 5: 47586 tokens (was 47586 in seed 42)\n",
      "Ratio 23: 47586 tokens (was 47586 in seed 42)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratios = {}\n",
    "for ratio in [5, 23]:\n",
    "    dfs = {}\n",
    "    for seed in [42, 1223, 1337]:\n",
    "        sweep_value = f\"ratio{ratio}_lbl0.08_compute0.004_seed{seed}\"\n",
    "        dfs[seed] = pd.read_csv(f'analysis_csvs/{sweep_value}.csv')\n",
    "\n",
    "    # Merge on token_id, not token string\n",
    "    df = dfs[42][['token_id', 'token', 'count', 'avg_size']].merge(\n",
    "        dfs[1223][['token_id', 'avg_size']], \n",
    "        on='token_id', \n",
    "        suffixes=('_42', '_1223')\n",
    "    )\n",
    "    df = df.merge(\n",
    "        dfs[1337][['token_id', 'avg_size']], \n",
    "        on='token_id'\n",
    "    )\n",
    "    df = df.rename(columns={'avg_size': 'avg_size_1337', 'count': 'count'})\n",
    "\n",
    "    # Calculate stats across seeds\n",
    "    df['mean_size'] = df[['avg_size_42', 'avg_size_1223', 'avg_size_1337']].mean(axis=1)\n",
    "    df['range'] = df[['avg_size_42', 'avg_size_1223', 'avg_size_1337']].max(axis=1) - \\\n",
    "                  df[['avg_size_42', 'avg_size_1223', 'avg_size_1337']].min(axis=1)\n",
    "    \n",
    "    print(f\"Ratio {ratio}: {len(df)} tokens (was {len(dfs[42])} in seed 42)\")\n",
    "    df.to_csv(f\"analysis_csvs/complete_merged_{ratio}.csv\",quoting=2)\n",
    "    ratios[ratio] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ecabcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_size_42</th>\n",
       "      <th>avg_size_1223</th>\n",
       "      <th>avg_size_1337</th>\n",
       "      <th>mean_size</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23257</td>\n",
       "      <td>Plug</td>\n",
       "      <td>1</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37682</td>\n",
       "      <td>HEAD</td>\n",
       "      <td>1</td>\n",
       "      <td>1194.666667</td>\n",
       "      <td>2218.666667</td>\n",
       "      <td>1706.666667</td>\n",
       "      <td>1706.666667</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44822</td>\n",
       "      <td>steel</td>\n",
       "      <td>2</td>\n",
       "      <td>1194.666667</td>\n",
       "      <td>2218.666667</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1649.777778</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41433</td>\n",
       "      <td>integer</td>\n",
       "      <td>3</td>\n",
       "      <td>1365.333333</td>\n",
       "      <td>1706.666667</td>\n",
       "      <td>2048.000000</td>\n",
       "      <td>1706.666667</td>\n",
       "      <td>682.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25795</td>\n",
       "      <td>ム</td>\n",
       "      <td>1</td>\n",
       "      <td>1365.333333</td>\n",
       "      <td>2218.666667</td>\n",
       "      <td>2389.333333</td>\n",
       "      <td>1991.111111</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47581</th>\n",
       "      <td>5198</td>\n",
       "      <td>appeal</td>\n",
       "      <td>120</td>\n",
       "      <td>3413.333333</td>\n",
       "      <td>2218.666667</td>\n",
       "      <td>2560.000000</td>\n",
       "      <td>2730.666667</td>\n",
       "      <td>1194.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47582</th>\n",
       "      <td>11615</td>\n",
       "      <td>struggled</td>\n",
       "      <td>65</td>\n",
       "      <td>3413.333333</td>\n",
       "      <td>2560.000000</td>\n",
       "      <td>2560.000000</td>\n",
       "      <td>2844.444444</td>\n",
       "      <td>853.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47583</th>\n",
       "      <td>49243</td>\n",
       "      <td>transpired</td>\n",
       "      <td>3</td>\n",
       "      <td>3413.333333</td>\n",
       "      <td>2389.333333</td>\n",
       "      <td>2560.000000</td>\n",
       "      <td>2787.555556</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47584</th>\n",
       "      <td>36190</td>\n",
       "      <td>underestimated</td>\n",
       "      <td>17</td>\n",
       "      <td>3413.333333</td>\n",
       "      <td>2218.666667</td>\n",
       "      <td>2560.000000</td>\n",
       "      <td>2730.666667</td>\n",
       "      <td>1194.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47585</th>\n",
       "      <td>447</td>\n",
       "      <td>&lt;447&gt;</td>\n",
       "      <td>50257</td>\n",
       "      <td>3754.666667</td>\n",
       "      <td>3754.666667</td>\n",
       "      <td>3925.333333</td>\n",
       "      <td>3811.555556</td>\n",
       "      <td>170.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47586 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       token_id            token  count  avg_size_42  avg_size_1223  \\\n",
       "0         23257             Plug      1  1024.000000    2048.000000   \n",
       "1         37682             HEAD      1  1194.666667    2218.666667   \n",
       "2         44822            steel      2  1194.666667    2218.666667   \n",
       "3         41433          integer      3  1365.333333    1706.666667   \n",
       "4         25795                ム      1  1365.333333    2218.666667   \n",
       "...         ...              ...    ...          ...            ...   \n",
       "47581      5198           appeal    120  3413.333333    2218.666667   \n",
       "47582     11615        struggled     65  3413.333333    2560.000000   \n",
       "47583     49243       transpired      3  3413.333333    2389.333333   \n",
       "47584     36190   underestimated     17  3413.333333    2218.666667   \n",
       "47585       447            <447>  50257  3754.666667    3754.666667   \n",
       "\n",
       "       avg_size_1337    mean_size        range  \n",
       "0        1536.000000  1536.000000  1024.000000  \n",
       "1        1706.666667  1706.666667  1024.000000  \n",
       "2        1536.000000  1649.777778  1024.000000  \n",
       "3        2048.000000  1706.666667   682.666667  \n",
       "4        2389.333333  1991.111111  1024.000000  \n",
       "...              ...          ...          ...  \n",
       "47581    2560.000000  2730.666667  1194.666667  \n",
       "47582    2560.000000  2844.444444   853.333333  \n",
       "47583    2560.000000  2787.555556  1024.000000  \n",
       "47584    2560.000000  2730.666667  1194.666667  \n",
       "47585    3925.333333  3811.555556   170.666667  \n",
       "\n",
       "[47586 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afed6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_5 = ratios[5]\n",
    "ratio_23 = ratios[23]\n",
    "\n",
    "\n",
    "\n",
    "ratio_23_corr = ratio_23['mean_size'].corr(ratio_23['count'],method='spearman') \n",
    "ratio_5_corr = ratio_5['mean_size'].corr(ratio_5['count'],method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ef2caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49926363582905003\n"
     ]
    }
   ],
   "source": [
    "print(ratio_23['mean_size'].corr(ratio_5['mean_size'],method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3eb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_23['avg_entropy_overall'] = df[[\"avg_entropy_42\",\"avg_entropy_1223\", \"avg_entropy\"]].mean(axis=1)\n",
    "ratio_5['avg_entropy_overall'] = df[[\"avg_entropy_42\",\"avg_entropy_1223\", \"avg_entropy\"]].mean(axis=1)\n",
    "import numpy as np\n",
    "print(ratio_23['mean_size'].corr(ratio_23['avg_entropy_overall'],method='spearman'),ratio_5['mean_size'].corr(ratio_5['avg_entropy_overall'],method='spearman'))\n",
    "\n",
    "for key in ratio_23.keys():\n",
    "    if ratio_23[key].dtype not in (np.float64, np.int64):\n",
    "        continue\n",
    "    else:\n",
    "        print(key,ratio_23['mean_size'].corr(ratio_23[key],method='spearman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7523550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_5.to_csv(path_or_buf=\"ratio_5_with_entropies.csv\",columns=[\"token_id_42\",\"token\",\"count_42\",\"avg_entropy_overall\"],quoting=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cf7bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900555283485903"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_23 = pd.read_csv('analysis_csvs/complete_merged_23.csv')\n",
    "df_5 = pd.read_csv('analysis_csvs/complete_merged_5.csv')\n",
    "\n",
    "df_23['mean_size'].corr(df_5['mean_size'],method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c08a6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09573435088352197"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = df_5.merge(df_23, on='token_id_42', suffixes=('_5', '_23'))\n",
    "merged['mean_size_5'].corr(merged['mean_size_23'], method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc090a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORRELATION BY FREQUENCY THRESHOLD ===\n",
      "(0.0, 10.0]         : n= 20975, Spearman=-0.0740\n",
      "(10.0, 50.0]        : n= 18218, Spearman=-0.0840\n",
      "(50.0, 100.0]       : n=  3825, Spearman=-0.0209\n",
      "(100.0, 500.0]      : n=  3657, Spearman=0.0853\n",
      "(500.0, 1000.0]     : n=   514, Spearman=0.1132\n",
      "(1000.0, 5000.0]    : n=   318, Spearman=0.2874\n",
      "(5000.0, inf]       : n=    77, Spearman=0.1257\n",
      "\n",
      "Frequency-weighted Pearson: -0.0400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "df5 = pd.read_csv('analysis_csvs/complete_merged_5.csv')\n",
    "df23 = pd.read_csv('analysis_csvs/complete_merged_23.csv')\n",
    "\n",
    "# Merge on token_id to align same tokens\n",
    "merged = df5.merge(df23, on='token_id_42', suffixes=('_5', '_23'))\n",
    "bins = [0,10,50,100,500,1000,5000,float('inf')]\n",
    "merged['freq_bin'] = pd.cut(merged['count_42_5'],bins=bins)\n",
    "# Correlation by frequency threshold\n",
    "print(\"=== CORRELATION BY FREQUENCY THRESHOLD ===\")\n",
    "for bin_label, group in merged.groupby('freq_bin',observed=True):\n",
    "    if len(group) > 10:\n",
    "        sp, _ = spearmanr(group['mean_size_5'], group['mean_size_23'])\n",
    "        print(f'{str(bin_label):20s}: n={len(group):6d}, Spearman={sp:.4f}')\n",
    "\n",
    "# Frequency-weighted correlation\n",
    "weights = np.log1p(merged['count_42_5'])\n",
    "cov_matrix = np.cov(merged['mean_size_5'], merged['mean_size_23'], aweights=weights)\n",
    "weighted_corr = cov_matrix[0,1] / np.sqrt(cov_matrix[0,0] * cov_matrix[1,1])\n",
    "print(f\"\\nFrequency-weighted Pearson: {weighted_corr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}